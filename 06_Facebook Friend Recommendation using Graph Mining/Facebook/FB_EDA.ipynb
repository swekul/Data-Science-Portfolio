{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnysF8x_ORlO"
   },
   "source": [
    "<p style=\"font-size:32px;text-align:center\"> <b>Social network Graph Link Prediction - Facebook Challenge</b> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkoerGBXORlS"
   },
   "source": [
    "### Problem statement: \n",
    "Given a directed social graph, have to predict missing links to recommend users (Link Prediction in graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3QpE6i9ORlU"
   },
   "source": [
    "### Data Overview\n",
    "Taken data from facebook's recruting challenge on kaggle https://www.kaggle.com/c/FacebookRecruiting  \n",
    "data contains two columns source and destination eac edge in graph \n",
    "    - Data columns (total 2 columns):  \n",
    "    - source_node         int64  \n",
    "    - destination_node    int64  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NHsD-3qlORlV"
   },
   "source": [
    "### Mapping the problem into supervised learning problem:\n",
    "- Generated training samples of good and bad links from given directed graph and for each link got some features like no of followers, is he followed back, page rank, katz score, adar index, some svd fetures of adj matrix, some weight features etc. and trained ml model based on these features to predict link. \n",
    "- Some reference papers and videos :  \n",
    "    - https://www.cs.cornell.edu/home/kleinber/link-pred.pdf\n",
    "    - https://www3.nd.edu/~dial/publications/lichtenwalter2010new.pdf\n",
    "    - https://www.youtube.com/watch?v=2M77Hgy17cg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJhG3ZczORlW"
   },
   "source": [
    "### Business objectives and constraints:  \n",
    "- No low-latency requirement.\n",
    "- Probability of prediction is useful to recommend ighest probability links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BUZLwsmKORlX"
   },
   "source": [
    "### Performance metric for supervised learning:  \n",
    "- Both precision and recall is important so F1 score is good choice\n",
    "- Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9a7HBOuQEcu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDE330RZORlY"
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "# please do go through this python notebook: \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv\n",
    "import pandas as pd#pandas to create small dataframes \n",
    "import datetime #Convert to unix time\n",
    "import time #Convert to unix time\n",
    "# if numpy is not installed already : pip3 install numpy\n",
    "import numpy as np#Do aritmetic operations on arrays\n",
    "# matplotlib: used to plot graphs\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns#Plots\n",
    "from matplotlib import rcParams#Size of plots  \n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans#Clustering\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "# to install xgboost: pip3 install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "import networkx as nx\n",
    "import pdb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKXT1GPXQLyM"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "import pandas as pd\n",
    "id = '1GpATd_pM4mcnWWIs28-s1lgqdAg2Wdv-'\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('preprocessed_data.csv')\n",
    "df=pd.read_csv('preprocessed_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dq7Di18AQzjW"
   },
   "outputs": [],
   "source": [
    "https://drive.google.com/file/d/1c5omWa9D1b4iQ28tiDfMs4wglhKKLA9X/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjYfNsR9QpdW"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "import pandas as pd\n",
    "id = '1c5omWa9D1b4iQ28tiDfMs4wglhKKLA9X'\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('train_woheader.csv')\n",
    "df=pd.read_csv('train_woheader.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnONHstVRRQA"
   },
   "outputs": [],
   "source": [
    "id = '1XNxqMI6qyXYhi2XVVRIxqD11hKgh2oja'\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('missing_edges_final.p')\n",
    "missing_edges = pickle.load(open('missing_edges_final.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1428,
     "status": "ok",
     "timestamp": 1595870417575,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "KYLceFoFSdRh",
    "outputId": "74e048b6-5e1a-45dc-e139-62472b0f11af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9437519"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLBu5J1JSdyC"
   },
   "outputs": [],
   "source": [
    "del (missing_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1YVbbdL1ORnW",
    "outputId": "6194a258-f8bd-42c5-87b9-a5ac25ce44f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "###generating bad edges from given graph\n",
    "import random\n",
    "if not os.path.isfile('data/after_eda/missing_edges_final.p'):\n",
    "    #getting all set of edges\n",
    "    r = csv.reader(open('data/after_eda/train_woheader.csv','r'))\n",
    "    edges = dict()\n",
    "    for edge in r:\n",
    "        edges[(edge[0], edge[1])] = 1\n",
    "        \n",
    "        \n",
    "    missing_edges = set([])\n",
    "    while (len(missing_edges)<9437519):\n",
    "        a=random.randint(1, 1862220)\n",
    "        b=random.randint(1, 1862220)\n",
    "        tmp = edges.get((a,b),-1)\n",
    "        if tmp == -1 and a!=b:\n",
    "            try:\n",
    "                if nx.shortest_path_length(g,source=a,target=b) > 2: \n",
    "\n",
    "                    missing_edges.add((a,b))\n",
    "                else:\n",
    "                    continue  \n",
    "            except:  \n",
    "                    missing_edges.add((a,b))              \n",
    "        else:\n",
    "            continue\n",
    "    pickle.dump(missing_edges,open('data/after_eda/missing_edges_final.p','wb'))\n",
    "else:\n",
    "    missing_edges = pickle.load(open('data/after_eda/missing_edges_final.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5uVz5oFdSJaj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1141,
     "status": "ok",
     "timestamp": 1595870373102,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "7gVf5nUwORnb",
    "outputId": "443fd9a4-030e-44d1-9e86-37cab0ac4c87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9437519"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJHTrPXEORng",
    "outputId": "2aa58c45-7a99-40cc-8882-653faa7837f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the graph with edges 9437519\n",
      "Number of nodes in the graph without edges 9437519\n",
      "============================================================\n",
      "Number of nodes in the train data graph with edges 7550015 = 7550015\n",
      "Number of nodes in the train data graph without edges 7550015 = 7550015\n",
      "============================================================\n",
      "Number of nodes in the test data graph with edges 1887504 = 1887504\n",
      "Number of nodes in the test data graph without edges 1887504 = 1887504\n"
     ]
    }
   ],
   "source": [
    " \n",
    "del missing_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qW7fX9OuORnk",
    "outputId": "abe6214e-5c52-4a64-b48d-ca59caed7df6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 1780722\n",
      "Number of edges: 7550015\n",
      "Average in degree:   4.2399\n",
      "Average out degree:   4.2399\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 1144623\n",
      "Number of edges: 1887504\n",
      "Average in degree:   1.6490\n",
      "Average out degree:   1.6490\n",
      "no of people common in train and test --  1063125\n",
      "no of people present in train but not present in test --  717597\n",
      "no of people present in test but not present in train --  81498\n",
      " % of people not there in Train but exist in Test in total Test data are 7.1200735962845405 %\n"
     ]
    }
   ],
   "source": [
    "if (os.path.isfile('data/after_eda/train_pos_after_eda.csv')) and (os.path.isfile('data/after_eda/test_pos_after_eda.csv')):        \n",
    "    train_graph=nx.read_edgelist('data/after_eda/train_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "    test_graph=nx.read_edgelist('data/after_eda/test_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "    print(nx.info(train_graph))\n",
    "    print(nx.info(test_graph))\n",
    "\n",
    "    # finding the unique nodes in the both train and test graphs\n",
    "    train_nodes_pos = set(train_graph.nodes())\n",
    "    test_nodes_pos = set(test_graph.nodes())\n",
    "\n",
    "    trY_teY = len(train_nodes_pos.intersection(test_nodes_pos))\n",
    "    trY_teN = len(train_nodes_pos - test_nodes_pos)\n",
    "    teY_trN = len(test_nodes_pos - train_nodes_pos)\n",
    "\n",
    "    print('no of people common in train and test -- ',trY_teY)\n",
    "    print('no of people present in train but not present in test -- ',trY_teN)\n",
    "\n",
    "    print('no of people present in test but not present in train -- ',teY_trN)\n",
    "    print(' % of people not there in Train but exist in Test in total Test data are {} %'.format(teY_trN/len(test_nodes_pos)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nHjj-khHORno"
   },
   "source": [
    "> we have a cold start problem here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UDT9PGNWORno",
    "outputId": "aca3d101-033d-4c51-9ce1-8cfd4cff2d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Number of nodes in the train data graph with edges 7550015\n",
      "Number of nodes in the train data graph without edges 7550015\n",
      "============================================================\n",
      "Number of nodes in the test data graph with edges 1887504\n",
      "Number of nodes in the test data graph without edges 1887504\n"
     ]
    }
   ],
   "source": [
    "#final train and test data sets\n",
    "if (not os.path.isfile('data/after_eda/train_after_eda.csv')) and \\\n",
    "(not os.path.isfile('data/after_eda/test_after_eda.csv')) and \\\n",
    "(not os.path.isfile('data/train_y.csv')) and \\\n",
    "(not os.path.isfile('data/test_y.csv')) and \\\n",
    "(os.path.isfile('data/after_eda/train_pos_after_eda.csv')) and \\\n",
    "(os.path.isfile('data/after_eda/test_pos_after_eda.csv')) and \\\n",
    "(os.path.isfile('data/after_eda/train_neg_after_eda.csv')) and \\\n",
    "(os.path.isfile('data/after_eda/test_neg_after_eda.csv')):\n",
    "    \n",
    "    X_train_pos = pd.read_csv('data/after_eda/train_pos_after_eda.csv', names=['source_node', 'destination_node'])\n",
    "    X_test_pos = pd.read_csv('data/after_eda/test_pos_after_eda.csv', names=['source_node', 'destination_node'])\n",
    "    X_train_neg = pd.read_csv('data/after_eda/train_neg_after_eda.csv', names=['source_node', 'destination_node'])\n",
    "    X_test_neg = pd.read_csv('data/after_eda/test_neg_after_eda.csv', names=['source_node', 'destination_node'])\n",
    "\n",
    "    print('='*60)\n",
    "    print(\"Number of nodes in the train data graph with edges\", X_train_pos.shape[0])\n",
    "    print(\"Number of nodes in the train data graph without edges\", X_train_neg.shape[0])\n",
    "    print('='*60)\n",
    "    print(\"Number of nodes in the test data graph with edges\", X_test_pos.shape[0])\n",
    "    print(\"Number of nodes in the test data graph without edges\", X_test_neg.shape[0])\n",
    "\n",
    "    X_train = X_train_pos.append(X_train_neg,ignore_index=True)\n",
    "    y_train = np.concatenate((y_train_pos,y_train_neg))\n",
    "    X_test = X_test_pos.append(X_test_neg,ignore_index=True)\n",
    "    y_test = np.concatenate((y_test_pos,y_test_neg)) \n",
    "    \n",
    "    X_train.to_csv('data/after_eda/train_after_eda.csv',header=False,index=False)\n",
    "    X_test.to_csv('data/after_eda/test_after_eda.csv',header=False,index=False)\n",
    "    pd.DataFrame(y_train.astype(int)).to_csv('data/train_y.csv',header=False,index=False)\n",
    "    pd.DataFrame(y_test.astype(int)).to_csv('data/test_y.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8QpQoOTORnr",
    "outputId": "d54e87b3-9dd3-47e8-fdde-f113dffb7cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points in train data (15100030, 2)\n",
      "Data points in test data (3775008, 2)\n",
      "Shape of traget variable in train (15100030,)\n",
      "Shape of traget variable in test (3775008,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data points in train data\",X_train.shape)\n",
    "print(\"Data points in test data\",X_test.shape)\n",
    "print(\"Shape of traget variable in train\",y_train.shape)\n",
    "print(\"Shape of traget variable in test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXslnUr1ORnu"
   },
   "outputs": [],
   "source": [
    "# computed and store the data for featurization\n",
    "# please check out FB_featurization.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "fjGhgPp2ORmH",
    "fCRpdjITORmu",
    "dZYvDAwDORnU",
    "JOFQEKhjORne"
   ],
   "name": "FB_EDA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
